% Copyright 2021 Google LLC
%
% Use of this source code is governed by an MIT-style
% license that can be found in the LICENSE file or at
% https://opensource.org/licenses/MIT.

%!BIB program = biber
%!TeX program = lualatex
%!TeX spellcheck = en-US

\documentclass[hctr2.tex]{subfiles}
\begin{document}
\section{Optimization of POLYVAL}\label{polyvalimpl}
The polynomial hash function is where the bulk of optimizations must be done. A naive partially-optimized implementation of $H$ is slower than XCTR mode. We use several optimization techniques to increase the efficiency of $H$. We show several methods to increase the parallelism of $H$ and to reduce the number of slow instructions required to compute it. With these optimizations in place, the polynomial hash function becomes significantly faster than XCTR mode.

\subsection{Precomputed powers}
Since $\hgen$ is constant during hashing, powers of $\hgen$ can be precomputed to avoid excess multiplications. 
\begin{algorithm}[H]
\caption{Fixed width polynomial evaluation}\label{polykalg}
\begin{algorithmic}[1]
	\Require $M$ is exactly $k$ blocks long.
	\Require $\hgen^1$, $\cdots$, $\hgen^{k-1}$ have been precomputed.
	\Procedure{PolyK}{$M$}
		\State $poly \gets 0^{128}$
		\State $i \gets 0$
		\For{$i \le k$}
		\State $poly \gets poly \oplus \hgen^{k-1-i}M[ni:n]$
		\EndFor
		\State \textbf{return} $poly$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
The subroutine \texttt{PolyK} allows $k$ blocks to be efficiently hashed at once. By adapting Horner's method, we can use \texttt{PolyK} as a subroutine to efficiently compute $poly(M)$.

\begin{algorithm}[H]
\caption{Polynomial evaluation}\label{polyalg}
\begin{algorithmic}[1]
	\Require $|M|$ is a multiple of block size.
	\Require $\hgen^1$, $\cdots$, $\hgen^{k}$ have been precomputed.
	\Procedure{Poly}{$M$}
		\State $poly \gets 0^{128}$
		\State $i \gets 0$
		\While{$|M| \ge kn(i+1)$}
			\State $poly \gets poly*\hgen^k \oplus \Call{PolyK}{M[ikn : kn]}$
			\State $i \gets i + 1$
		\EndWhile
		\State $m \gets |M| - kni$\Comment{$0 \le m < k$}
		\State $j \gets 0$
		\State $\poly \gets \poly*\hgen^m$
		\While{$jn < m$}
		\State $poly \gets \hgen^{m-j-1}M[ikn + jn : n]$
		\EndWhile
		\State \textbf{return} $poly$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
Notice that each invocation of $\texttt{PolyK}$ requires $k$ multiplications. Let $s$ be the number of invocations of \texttt{PolyK} and $m = |M| \bmod nk$. An invocation of \texttt{Poly} requires $s(k+1) + m$ finite field multiplications. Since $s(k+1) + m$ is constant for any choice of $k$, we can use any choice of $k$ and retain the same number of multiplications required to compute \texttt{Poly}. Furthermore, $\texttt{PolyK}$ is parallelizable, so larger values of $k$ are preferred. Our implementation uses $k = 4$ for both x86-64 and ARM64.

\subsection{Hardware accelerated multiplication}
Finite field multiplication for HCTR2 consists of two subroutines, polynomial multiplication and polynomial reduction. We use a well-known variant of Karatsuba multiplication for polynomial multiplication and a well-known variant of Barrett reduction for polynomial reduction \cite{CLMUL}. We describe these algorithms for completeness.

Let the input operands to polynomial multiplication be 128-bit polynomials $A, B$. We split $A, B$ into two 64-bit parts, $A = [A_1 : A_0]$, $B = [B_1 : B_0]$. Note that these values are assumed to be in registers, so the little-endian specification no longer applies. In other words, the lowest bit of $A_0$ is the constant term of $A$ and the highest bit of $A_1$ is the $x^{127}$ term. Let $clmul(X, Y)$ be the 128-bit carry-less product of two 64-bit operands. The following pseudocode describes Karatsuba multiplication for 128-bit polynomials $A, B$.
\begin{algorithm}[H]
\caption{Karatsuba multiplication for 128-bit polynomials}\label{karatsuba}
\begin{algorithmic}[1]
	\Require $A, B$ are 128-bit polynomials.
	\Procedure{KaratsubaStep1}{A, B}
		\State $C \gets clmul(A_1, B_1)$\Comment{$C = [C_1 : C_0]$}
		\State $D \gets clmul(A_0, B_0)$\Comment{$D = [D_1 : D_0]$}
		\State $E \gets clmul(A_0 \oplus B_0, A_1 \oplus B_1)$\Comment{$E = [E_1 : E_0]$}
		\State \textbf{return} $C, D, E$
	\EndProcedure
	\State
	\Procedure{KaratsubaStep2}{C, D, E}
		\State \textbf{return} $[C_1 : C_0 \oplus C_1 \oplus D_1 \oplus E_1 : D_1 \oplus C_0 \oplus D_0 \oplus E_0 : D_0]$
	\EndProcedure
	\State
	\Procedure{Karatsuba}{$A, B$}
		\State $C, D, E \gets \Call{KaratsubaStep1}{A, B}$
		\State \textbf{return} $\Call{KaratsubaStep2}{C, D, E}$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
We now describe the polynomial reduction algorithm. This is the slight modification of the process described in \cite{CLMUL}. This modification allows us to use carry-less multiplication instructions instead of bitshifts. Let $p(x) = [X_3 : X_2 : X_1 : X_0]$ be the $256$-bit operand. To compute the 128-bit reduction, we only need to reduce the upper 128-bit polynomial then XOR the reduction with the lower 128-bits. Let $c(x) = [X_3 : X_2]$ be the polynomial representing the upper 128-bits of the operand. Let $g(x)$ be the modulus and $g^*(x)$ be the lower 128-bits of the modulus. Since we assume the modulus to be $x^{128} + x^7 + x^2 + x + 1$, we have $g^*(x) = [\text{0x0} : \text{0x87}]$. Finally, let $q^+(x)$ be $x^{256}/g(x)$, in this case $q^+(x) = g(x)$. First we compute the 256-bit product of $q^+$ and $c(x)$ then discard the lower 128 bits. Let the operator $p(x) \div x^{n}$ represent polynomial long division without remainder by $x^n$ or equivalently, bitshifting right by $n$.
\begin{gather*}
       y(x) = q^+(x)c(x) = [Y_3 : Y_2 : Y_1 : Y_0]\\
       y^*(x) = y(x) \div x^{128} \bmod x^{128} = [Y_3 : Y_2]
\end{gather*}
However, notice in this case that
\begin{gather*}
       y^*(x) = c(x)(x^{128} + g^*(x)) \div x^{128} \mod x^{128}\\
       = [c(x)x^{128} + c(x)g^*(x)] \div x^{128} \mod x^{128}\\
       = c(x) + (g^*(x)c(x) \div x^{128}) \mod x^{128}
\end{gather*}
Since $deg(g^*(x)) < 64$ we have $deg(g^(x)c(x)) < 192$. Furthermore, since we wish to compute $g^*(x)c(x) \div x^{128}$, we only need to compute the polynomial terms $a_{191}x^{192} + \cdots + a_{127}x^{128}$. Therefore we have
\begin{align*}
       (c(x) \div x^{64})g^*(x) \div x^{64} = g^*(x)c(x) \div x^{128}
\end{align*}
Substituting this into our original equation gives:
\begin{gather*}
       y^*(x) = c(x) + ((c(x) \div x^{64})g^*(x)) \div x^{64} \mod x^{128}\\
       = (c(x) \div x^{64})(x^{64}) + (c(x) \bmod x^{64}) + ((c(x) \div x^{64})g^*(x)) \div x^{64} \mod x^{128}
\end{gather*}
Let $t(x) = c(x) \div x^{64}g^*(x)$. This gives
\begin{align*}
       y^*(x) = (c(x) \div x^{64})x^{64} + (c(x) \text{ mod } x^{64}) + t(x) \div x^{64} \mod x^{128}
\end{align*}
Furthermore, $t(x)$ is efficiently computable using carry-less multiplication.
\begin{align*}
       t(x) = (c(x) \div x^{64})g^*(x) = [T_1 : T_0] = clmul(X_3, \texttt{0x87})
\end{align*}
To compute the final reduction of $c(x)$, we then multiply $y^*(x)$ by $g^*(x)$ and return the lowest 128 bits of the product.
\begin{align*}
       r(x) = g^*(x)y^*(x) = t(x)x^{64} + g^*(x)\left[(c(x) \text{ mod } x^{64}) + (t(x) \div x^{64})\right]
\end{align*}
For simplicity let $z(x) = g^*(x)\left[(c(x) \text{ mod } x^{64}) + (t(x) \div x^{64})\right]$. Notice that this is also efficiently computable with carry-less multiplication.
\begin{align*}
       z(x) = [Z_1 : Z_0] = clmul(X_2 \oplus T_1,\texttt{0x87})
\end{align*}
So our final computation of $r(x)$ is
\begin{align*}
       r(x) = [T_0 \oplus Z_1 : Z_0] \oplus [X_1 : X_0]
\end{align*}
The following describes the same process in pseudocode.
\begin{algorithm}[H]
	\caption{Barrett reduction modulo $x^{128} + x^7 + x^2 + x + 1$}\label{barrett}
\begin{algorithmic}[1]
	\Require $X$ is a 256-bit polynomial.
	\Procedure{Barrett}{$X$} \Comment{$X = [X_3 : X_2 : X_1 : X_0]$}
		\State $T \gets clmul(X_3, \texttt{0x87})$\Comment{$T = [T_1 : T_0]$}
		\State $Z \gets clmul(X_2 \oplus T_1, \texttt{0x87})$ \Comment{$Z = [Z_1 : Z_0]$}
		\State \textbf{return} $[T_0 \oplus Z_1 \oplus X_1 : Z_0 \oplus X_0]$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
Combining Karatsuba multiplication and Barrett reduction allows us to compute finite field multiplications.
\begin{algorithm}[H]
	\caption{Naive GF128 Multiplication}\label{GF128Naive}
\begin{algorithmic}[1]
	\Require $A, B$ are 128-bit polynomials.
	\Procedure{GF128}{$A, B$}
		\State $P \gets \Call{Karatsuba}{A, B}$
		\State $R \gets \Call{Barrett}{P}$
		\State \textbf{return} $R$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
This approach greatly increases the speed of $H$, but it still has several problems. A single finite field multiplication requires 5 carry-less multiplications when implemented in this way, so an invocation to $\texttt{PolyK}$ requires $5k$ carry-less multiplications. Furthermore, polynomial reduction requires an abundance of registers to implement. This makes a naive implementation of $\texttt{PolyK}$ slow and difficult to parallelize on architectures where vectorized registers are scarce, such as x86-64. We fix this problem in the next subsection.

\subsection{Amortized reductions and parallelism}
The observation that $\texttt{PolyK}$ is done only with pre-computed 128-bit polynomials leads to a large speedup in the implementation of $H$. The basic idea is to only perform a single polynomial reduction per invocation of $\texttt{PolyK}$. Instead of performing polynomial multiplication in $GF_{128}$, we will simply perform multiplication in $GF_{2}[x]$. Since all multiplicands are pre-computed 128-bit polynomials, the output will always be a 256-bit polynomial. If we XOR all 256-bit polynomials together, we can then perform a single polynomial reduction at the end to compute the final output in $GF_{128}$.

In practice, we change this idea slightly. Instead of producing a 256-bit polynomial by completing the full Karatsuba multiplication, we instead only perform the first step of Karatsuba multiplication by computing $C_i$, $D_i$, and $E_i$. We then compute the following
\begin{algorithm}[H]
	\caption{Parallelized GF128 multiplication}\label{parallelgf128}
\begin{algorithmic}[1]
	\Require All $A_i, B_i$ are 128-bit polynomials.
	\Procedure{KaratsubaStep1Parallel}{$\{A_0, \cdots, A_{k-1}\}, \{B_0, \cdots, B_{k-1}\}$}
		\State $C \gets 0^{128}$
		\State $D \gets 0^{128}$
		\State $E \gets 0^{128}$
		\For{$i \gets 0, i < k$}
			\State $C', D', E' \gets \Call{KaratsubaStep1}{A_i, B_i}$\Comment{Compute in parallel.}
			\State $C \gets C \oplus C'$
			\State $D \gets D \oplus D'$
			\State $E \gets E \oplus E'$
		\EndFor
		\State \textbf{return} $C, D, E$
	\EndProcedure
	\State
	\Procedure{GF128Parallel}{$\{A_0, \cdots, A_{k-1}\}, \{B_0, \cdots, B_{k-1}\}$}
		\State $C, D, E \gets \Call{KaratsubaStep1Parallel}{\{A_0, \cdots, A_{k-1}\}, \{B_0, \cdots, B_{k-1}\}$}
		\State $P \gets \Call{KaratsubaStep2}{C, D, E}$
		\State $R \gets \Call{Barrett}{P}$
		\State \textbf{return} $R$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
Using this method as a subroutine to compute $\texttt{PolyK}$ allows the complex parts of polynomial multiplication to only be computed once per invocation of $\texttt{PolyK}$.

This implementation only requires $3k + 2$ carry-less multiplications per invocation of $\texttt{PolyK}$. Furthermore, it allows for greater parallelism since the first step of Karatsuba multiplication can be done using only 4 registers on x86-64.

\subsection{Further parallelism}
A minor problem with the implementation of $\texttt{PolyK}$ is that when computing $\texttt{Poly}(M)$ the outer multiplications by $\hgen^{k}$ cannot be parallelized. This can be fixed by precomputing the first $ck$ powers of $\hgen$ for some integer $c$. This allows for a variant on the definition of $\texttt{PolyK}$ which we will call $\texttt{PolyInternal}$.

Using this idea, we can remove the non-parallelism of $\hgen^k$ and further amortize polynomial reductions. The following pseudocode describes a fully parallelized implementation of $\texttt{Poly}$.
\begin{algorithm}[H]
\caption{Subroutine for parallelized polynomial evaluation}\label{polyalgsub}
\begin{algorithmic}[1]
	\Require $|Q| < nkc$
	\Require $\hgen^1$, $\cdots$, $\hgen^{kc}$ have been precomputed.
	\Procedure{PolyInternal}{$Q$}
		\State $poly \gets 0^{128}$
		\State $nblocks \gets \lfloor |Q|/n \rfloor$
		\State $nstrides \gets \lfloor nblocks/c \rfloor$
		\State $C \gets 0^{128}$
		\State $D \gets 0^{128}$
		\State $E \gets 0^{128}$
		\For{$i = 0, i < nstrides$}
			\State $e \gets nblocks - 1 - ci$
			\State $Alist \gets \{Q[nci + 0 : n], \cdots, Q[nci + n(k - 1) : n]\}$
			\State $Blist \gets \{\hgen^{e}, \cdots, \hgen^{e - k + 1}\}$
			\State $C', D', E' \gets \Call{KaratsubaStep1Parallel}{Alist, Blist}$
			\State $C \gets C \oplus C'$
			\State $D \gets D \oplus D'$
			\State $E \gets E \oplus E'$
		\EndFor
		\For{$i = 0, i < nblocks \bmod c$}
			\State $e \gets nblocks - 1 - i$
			\State $C', D', E' \gets \Call{KaratsubaStep1}{Q[nc*nstrides + ni : n], \hgen^{e}}$
			\State $C \gets C \oplus C'$
			\State $D \gets D \oplus D'$
			\State $E \gets E \oplus E'$
		\EndFor
		\State $P \gets \Call{KaratsubaStep2}{C, D, E}$
		\State $R \gets \Call{Barrett}{P}$
		\State \textbf{return} $R$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Parallelized polynomial evaluation}\label{polyalg}
\begin{algorithmic}[1]
	\Require $\hgen^1$, $\cdots$, $\hgen^{kc}$ have been precomputed.
	\Procedure{Poly}{$M$}
		\State $poly \gets 0^{128}$
		\For{$i = 0, i < \lceil |M| / c \rceil$}
			\State $poly \gets poly*\hgen^{kc} \oplus \Call{PolyInternal}{M[icn : cn]}$
		\EndFor
		\State \textbf{return} $poly$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
The number of polynomial reductions is reduced further for larger choices of $c$ since $\texttt{PolyInternal}$ only requires a single invocation of polynomial reduction.

\end{document}
